# Overview

This file is meant to provide an overview of the project, useful tools I've found during research, and any notes that I have about the project as I move forward

## Project Description: Implement Q&A against documentation with semantic search and ChatGPT

I believe that a prototype (for example a workflow that answers a given question) should be easy to build with the following steps:
1. Clone https://github.com/parallelworks/docs 
2. Run a semantic search to find which files (*.md and *.mdx) in the docs are relevant to answer a given question
3. Glue these files together and pass them to the ChatGPT API together with the question 
â€‹
I believe step 2 (finding the relevant files) is the hardest of all. Step 1 is trivial and there are many examples for step 3. Also, step 2 on its own would be nice to have.

## Useful Python libraries for implementing semantic search

### For analyzing data from `.md` files in the Github repo:

**Markdown**: Reads the content of `.md` files and extracts the text data into plain text for analysis

### For actual semantic search:

**NLTK**: Provides tools for natural language processing, such as tokenization, stemming, and lemmatization.

**Gensim**: Offers implementations of various word embedding models like Word2Vec and GloVe.

**Scikit-learn**: Provides methods for feature extraction and vectorization, such as TF-IDF.

**Annoy**: A library for approximate nearest neighbor search, which can be useful for efficient indexing and retrieval.

