{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation Data Reader\n",
    "\n",
    "This Jupyter notebook is meant to serve as an introduction to reading Github `.md` documentation and analyzing it.."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading and Storing the Documentation Data\n",
    "\n",
    "In this section, we'll read the markdown `.md` file data, collect it, and store it for processing. We can do this by reading through all of the `.md` files in a directory and reading them into plain text format, then storing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def read_md_file(filepath: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads a markdown file and processes it into a string of plain text.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str) : the filepath of the markdown file to read\n",
    "    \n",
    "    Returns:\n",
    "        text (str) : the plain text from the inputted markdown file\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        content = f.read()\n",
    "        html = markdown.markdown(content)\n",
    "        text = ''.join(BeautifulSoup(html).findAll(text=True))\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/lp_w7fr92mj40y7_28ynvst40000gn/T/ipykernel_33684/3585446199.py:17: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  text = ''.join(BeautifulSoup(html).findAll(text=True))\n"
     ]
    }
   ],
   "source": [
    "text = read_md_file(\"../intro/proj-overview.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def collect_doc_data(directory: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scans through a directory and collects the documentation data from all\n",
    "    '.md' files into a list.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str) : directory to scan through\n",
    "    \n",
    "    Returns\n",
    "        docs_data (list[str]) : documentation data from `.md` files\n",
    "    \"\"\"\n",
    "    doc_data = []\n",
    "    for dirpath, _, filenames in os.walk(directory):\n",
    "        for file in filenames:\n",
    "            if file.endswith('.md'):\n",
    "                file_path = os.path.join(dirpath, file)\n",
    "                text = read_md_file(file_path)\n",
    "                doc_data.append(text)\n",
    "    \n",
    "    return doc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/lp_w7fr92mj40y7_28ynvst40000gn/T/ipykernel_33684/3585446199.py:17: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  text = ''.join(BeautifulSoup(html).findAll(text=True))\n"
     ]
    }
   ],
   "source": [
    "doc_data = collect_doc_data(\"../docs/docs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Cleaning the Documentation Data\n",
    "\n",
    "In this section, we'll take our collected and stored documentation data from Step 1 and clean it up so we can use it. This could include removing HTML tags, removing punctuation and special characters, removing extra whitespaces from the text, making all of our text lowercase for semantic searching, and catching any mispellings in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc_data(doc_data: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Clean the documentation data by removing HTML tags, removing punctuation\n",
    "    and special characters, removing extra whitespaces, making everything\n",
    "    lowercase, and catching mispelled words.\n",
    "\n",
    "    Parameters:\n",
    "        doc_data (list[str]) : the collected and read `.md` data\n",
    "    \n",
    "    Returns:\n",
    "        cleaned_doc_data (list[str]) : the cleaned documentation data\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Pre-processing the Documentation Data\n",
    "\n",
    "In this section, we'll take our cleaned documentation data from Step 2 and pre-process it by tokenization, stemming lemmatization, and stop-word removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_doc_data(cleaned_doc_data: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Preprocess the documentation data by tokenization, stemming\n",
    "    lemmatization, and stop-word removal.\n",
    "\n",
    "    Parameters:\n",
    "        cleaned_doc_data (list[str]) : the cleaned documentation data\n",
    "    \n",
    "    Returns:\n",
    "        proc_doc_data (list[str]) : preprocessed documentation data\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
