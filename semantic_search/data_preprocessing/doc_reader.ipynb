{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation Data Reader\n",
    "\n",
    "This Jupyter notebook is meant to serve as an introduction to reading Github `.md` documentation and analyzing it.."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading and Storing the Documentation Data\n",
    "\n",
    "In this section, we'll read the markdown `.md` file data, collect it, and store it for processing. We can do this by reading through all of the `.md` files in a directory and reading them into plain text format, then storing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def read_md_file(filepath: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads a markdown file and processes it into a string of plain text.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str) : the filepath of the markdown file to read\n",
    "    \n",
    "    Returns:\n",
    "        text (str) : the plain text from the inputted markdown file\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        content = f.read()\n",
    "        html = markdown.markdown(content)\n",
    "        text = ''.join(BeautifulSoup(html).findAll(text=True))\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/lp_w7fr92mj40y7_28ynvst40000gn/T/ipykernel_33684/3992071256.py:17: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  text = ''.join(BeautifulSoup(html).findAll(text=True))\n"
     ]
    }
   ],
   "source": [
    "text1 = read_md_file(\"../proj-overview.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def collect_doc_data(directory: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scans through a directory and collects the documentation data from all\n",
    "    '.md' files into a list.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str) : directory to scan through\n",
    "    \n",
    "    Returns\n",
    "        docs_data (list[str]) : documentation data from `.md` files\n",
    "    \"\"\"\n",
    "    doc_data = []\n",
    "    for dirpath, _, filenames in os.walk(directory):\n",
    "        for file in filenames:\n",
    "            if file.endswith('.md'):\n",
    "                file_path = os.path.join(dirpath, file)\n",
    "                text = read_md_file(file_path)\n",
    "                doc_data.append(text)\n",
    "    \n",
    "    return doc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/lp_w7fr92mj40y7_28ynvst40000gn/T/ipykernel_33684/3992071256.py:17: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  text = ''.join(BeautifulSoup(html).findAll(text=True))\n"
     ]
    }
   ],
   "source": [
    "doc_data = collect_doc_data(\"../docs/docs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Cleaning the Documentation Data\n",
    "\n",
    "In this section, we'll take our collected and stored documentation data from Step 1 and clean it up so we can use it. This could include removing HTML tags, removing punctuation and special characters, removing extra whitespaces from the text, making all of our text lowercase for semantic searching, and catching any mispellings in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_punct_and_special_chars(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes punctuation and special characters using Regex\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\w\\s]', '', input_str)\n",
    "\n",
    "def remove_whitespace(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes whitespace from an input string.\n",
    "    \"\"\"\n",
    "    return ' '.join(input_str.split())\n",
    "\n",
    "def clean_str(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Applies data cleaning to input string.\n",
    "    \"\"\"\n",
    "    return remove_punct_and_special_chars(remove_whitespace(input_str).lower())\n",
    "\n",
    "def clean_doc_data(doc_data: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Clean the documentation data by removing HTML tags, removing punctuation\n",
    "    and special characters, removing extra whitespaces, making everything\n",
    "    lowercase, and catching mispelled words.\n",
    "\n",
    "    Parameters:\n",
    "        doc_data (list[str]) : the collected and read `.md` data\n",
    "    \n",
    "    Returns:\n",
    "        cleaned_doc_data (list[str]) : the cleaned documentation data\n",
    "    \"\"\"\n",
    "    return [clean_str(i) for i in doc_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_doc_data = clean_doc_data(doc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sidebar_position 6 working with cloud snapshots cloud snapshots let you make persistent changes to the operating system image running on your cluster nodes by using an image provided by parallel works as a base you can stage automations install additional software or enable additional services creating cloud snapshots navigate to your account settings username  account in profile settings click cloud snapshots in cloud snapshots click new snapshot snapshot configuration settings there are several configurable parameters for cloud snapshots which are outlined below type use this dropdown menu to select whether your snapshot will be built for aws azure or google cloud account use this dropdown menu to select which cloud account will provision your snapshot for most users this menu should be left as the default option unless youre a member of multiple organizations group use this dropdown menu to select the group name that your organization uses to allocate costs this menu is especially important if your organization uses multiple groups if youre not sure which group to select you can contact us or your organizations pw platform administrator snapshot region use this dropdown menu to select the region your snapshot will be provisioned in if you run in multiple regions you will want to provision the snapshot wherever you run your clusters base image use this dropdown menu to select the pw image that will be the base for your snapshot typically this menu will be populated with the suggested version by default root disk size gb use this field to enter the size of the snapshots root disk by default this field is set to 100 typically you wont have to change this value unless you run into capacity issues name use this field to enter the name of your snapshot as it will be listed on the pw platform description use this field to enter a description to provide additional details about your snapshot snapshot build script you can enter a script in snapshot build script which will run to make additions to the base pw image you can use this script to install additional packages from yum repositories clone github repositories or download files from a url an example build script is provided below bash binbash get useful environment info echo my username is user echo my home dir is home echo my workdir is pwd clone a public github repository git clone httpsgithubcomhpciorgit usrlocalsrcior install anaconda and have it initialize on login wget httpsrepoanacondacomarchiveanaconda3202303linuxx86_64sh sh anaconda3202303linuxx86_64sh b p usrlocalanaconda3 symlink the conda executable to the main usrlocalbin directory ln s usrlocalanaconda3binconda usrlocalbinconda install jupyter conda install y jupyter packages will be installed under the anaconda root directory so symlink what you need ln s usrlocalanaconda3binjupyterlab usrlocalbinjupyterlab ln s usrlocalanaconda3binjupyter usrlocalbinjupyter install r and r studio server specify the r version you want export r_version413 download and install r packages curl o httpscdnrstudiocomrcentos7pkgsrr_version11x86_64rpm yum y install rr_version11x86_64rpm  note this package installs r to optr413binr install r studio packages wget httpsdownload2rstudioorgservercentos7x86_64rstudioserverrhel2023030386x86_64rpm yum y install rstudioserverrhel2023030386x86_64rpm  this build script will print some basic environment information clone the public ior repository from github into usrlocalsrcior download and run the conda installer download and install r and r studio server link executables to a common path location once youve provided your build script click create snapshot to save the configuration provisioning cloud snapshots after clicking create snapshot the page will update with a provisioning log and two new buttons save snapshot config and provision snapshot click save snapshot config when making configuration changes that you want to save including changes to the main parameters click provision snapshot to start building the snapshot image doing so will replace the snapshot build script with the provisioning log where you can monitor the snapshot build the snapshot build process works by creating a temporary virtual machine vm that runs the pw base image then the provided script runs to make additions to the image which is saved as a separate snapshot when the snapshot is done building the provisioning log will show a message identifying the name of the image in the csp account if there were errors in the build that prevented it from completing those will also be visible in the log if your build is successful the provisioning log will show a message such as json packer build completed successfully snapshot_idami0a5854d925e6e558b snapshot_namepwdemohello cspaws regionuseast1  httpsparallelworksapiv2machineimages if your build is unsuccessful the provisioning log will show a message such as json build amazonebsaws errored after 1 minute 57 seconds script exited with nonzero exit status 1 allowed exit codes are 0  wait completed after 1 minute 57 seconds  some builds didnt complete successfully and had errors  amazonebsaws script exited with nonzero exit status 1 allowed exit codes are 0  builds finished but no artifacts were created packer build failed info note if you reprovision an existing snapshot and the new build has errors your previously working snapshot will not be overwritten  using cloud snapshots snapshots you have created for any csp will automatically be added to your cluster configuration settings you can see usercreated snapshots on a clusters configuration page by selecting the image in controller settings and the elastic image in partition settings you can also configure a different snapshot for your controller and each of your partitions deleting cloud snapshots to delete a custom snapshot navigate to its configuration page and click deprovision snapshot a dialog box will appear with the message are you sure you want to deprovision the snapshot test click deprovision snapshot in the dialog box the provisioning log will then display the deletion process json starting delete of custom image cloud aws region useast1 project cacloudmgmt image pwdemohello ami ami023b3386461fdfad6 snapshotid snap01d59ca427982c1d8 aws ec2 deregisterimage imageid ami023b3386461fdfad6 aws ec2 deletesnapshot snapshotid snap01d59ca427982c1d8 delete completed  if you use the method above you will still have your snapshot listed in cloud snapshots username  account  cloud snapshots and you will be able to reconfigure and reprovision the snapshot at any time alternatively you can delete a snapshot from the list in cloud snapshots if you click the delete icon  a dialog box will appear with the message are you sure you want to delete the snapshot snapshot name clicking delete snapshot will permanently remove the snapshot from your account and from the list in cloud snapshots info about deletion if you want to delete a snapshot from the list in cloud snapshots you first need to deprovision the snapshot on its configuration page if you dont the snapshot will still exist in your csp account ',\n",
       " 'sidebar_position 12 label getting support getting support if youre experiencing problems with the pw platform were here to help you can check the platform status at any time by clicking status on the login page or in the bottomleft corner after you log in you can submit a help ticket by emailing us at supportparallelworkscom',\n",
       " 'sidebar_position 11 sidebar_label navigating the admin panel title  about the admin panel this page explains the features in the admin panel which you can access by clicking your username and selecting admin info persona youll only be able to access these features if youre a pw platform administrator  info about containers in much of the user guide we say user workspaces to talk about a users account on the platform please note that this term is synonymous with user container which we use on this page  platform settings when you navigate to the admin panel youll see platform settings by default this tab displays essential information about your organizations version of the platform you can also manage maintenace mode from this tab while this mode is enabled only admins will be able to start and stop resources to enable maintenance mode click the checkbox next to it click save platform settings your changes will be applied immediately the platform will remain in maintenance mode until you deactivate it users this tab displays all of your users information including username email address api key active status container image account creation date use the username field to search for users use the active dropdown menu to display users that are active inactive or either this option is set to either by default use the limit dropdown menu to narrow the listed users to 10 20 50 100 or all this option is set to 50 by default editing user information in the users tab click on the username youd like to edit on the next page you can edit several of the users parameters the first section contains information about the users account container and access to the platform identity here you can edit a users username or email altering either of these parameters will change the users login credentials settings here you can control a users access to the platform user host this field identifies the user host which is the part of the platform where account resources are provisioned we recommend contacting us before you make changes to this parameter user container this option identifies which service will be used to deploy a users container use the bubbles to select docker or k8s kubernetes we recommend contacting us before you make changes to this parameter mfa enabled use the bubbles to select whether the user will use multifactor authentication select no if a user doesnt need multifactor authentication select myproxy if you work with a governmental agency such as a public university or a research organization generally myproxy is preferred for these types of institutions select duo if you work with a company or organization that is not affiliated with the government duo is a cisco service that is more popular with other types of institutions we recommend contacting us before you make changes to this parameter user container image name this field identifies which ide service we use to house a users container currently we use theia for all user containers we recommend contacting us before you make changes to this parameter user container image version this field identifies which image version a users container is running by default this field is set to latest we recommend contacting us before you make changes to this parameter user organization use this dropdown menu to assign the user to an organization attributes here you can control whether a user is an admin or active by selecting their respective checkboxes a user with admin enabled will be able to access the admin panel and all of its settings this option does not affect the group setting orgadmin for more information please see about roles a user with active enabled will be able to log in to the platform with their username and password unchecking active will disable a users access to the platform actions click the update user container button to migrate a users container to the latest image click the kill user container button to restart a users container click the remove from teams button to remove a user from all of their assigned groups info note if you change any of the parameters above click save before leaving the page your changes will be applied immediately  set password here you can reset a users login credentials if you change this parameter click save before leaving the page your change will be applied immediately contact info here you can change a users contact information including their display name platform url and geographical location this information is only visible to platform admins and does not affect a users login credentials if you change these parameters click save before leaving the page your changes will be applied immediately setting user images in the users tab select users with their checkboxes click set image a dialog box will appear enter the image name and the image version click apply massupdate your changes will be applied immediately updating user images in the users tab select users with their checkboxes click update inplace a dialog box will appear confirm that youve selected the users you want to update click apply massupdate your changes will be applied immediately groups this tab displays information for all of your groups including name organization number of members allocation amount percentage of allocation used state creation date id number all the functions in managing groups can be completed from this tab as well keys the keys tab shows information for all of your cloud account keys including their name which organization owns the key the creation date and the key id you can manage your cloud account keys in this tab if you click the name of a key you can edit its name and description on the next page click save after making any changes you can also permanently delete the key from the platform by clicking the delete button please note that if youve used a key to provision infrastructure you wont be able to delete that key until youve deprovisioned the infrastructure info note if you need to add a key to the platform please see adding a cloud account  instances this tab displays information for all of your instances including csp organization that owns the key region instance id creation date instance name if any instance type private ip public ip cloud state estimated cloud state time pw state please note that the instance list is wider than most monitors so the included screenshot does not show all of the fields listed above to see more information about your instances scroll to the bottom of the page and use the horizontal scroll bar to show more columns you can configure your instance types on the platform by organizations for more information please see configuring instance types containers this tab displays information for all of your user containers including container name user container image image version current image version on the platform creation date type docker or kubernetes killing user containers in the containers tab select users with their checkboxes click kill containers a dialog box will appear confirm that youve selected the containers you want kill click apply massupdate your changes will be applied immediately reports this tab displays information for your reports including type of report email address that receives reports who the report monitors frequency creator creation date creating reports in the reports tab click  add new report on the next page you can edit the parameters listed below use the type dropdown menu to select the type of report you want to generate summary project monthly user application use the who field to enter the username who the report will monitor use the email field to enter the report recipients email address use the frequency bubbles to select how frequently the report will be generated daily weekly monthly event once at the time of creation test once at the time of creation disable end reports for the time being',\n",
       " 'sidebar_position 1 label about the platform slug  about the platform what we do our platform gives users the ability to create and manage elastic resource pools and highperformance computing hpc clusters on virtually any cloud service provider the platform is designed to be accessible and universally useful users can run scriptscalled workflowsthat are defined in a variety of programming languages across multiple pools and clusters pw customers use their own cloud accounts to deploy cloud hpc resources via the pw platform meaning that hpc resources are our customerdeployed solution while the pw platform can be deployed in different locations ie in the cloud or onpremise it is not deployed by customers directly our goal is to make highperformance simulation and modeling computation as simple as possible and were working towards that goal every day working with cloud resources the process for using cloud resources typically follows these steps log in to the pw platform create or start a cluster with the configuration that best suits your work transfer your data to the cloud from an onpremise location or from an object storage such as amazon web services aws s3 buckets google cloud storage gcs buckets or microsoft azure blob containers complete your computations transfer your data back to an onpremise location or to object storage shut down the cluster essential cloud concepts clusters are standard hpc clusters wellsuited for supporting the execution of a wide range of parallel applications including mpi openmp and gpubased applications as well as various hybrid combinations cloudbased clusters can run a variety of job schedulers providing an environment thats familiar to users of traditional hpc clusters on the pw platform a cluster has one controller node that sends jobs to the compute nodes which are grouped into partitions pools are collections of compute resources such as a group of nearly identical cloud worker instances pools are directly managed by pw infrastructure in an elastic fashion workers in pools can connect directly to the pw platform and to each other workflows are scripts written in a variety of languages and programming models typically workflows orchestrate the execution of applications relevant to your domain whether thats computational fluid dynamics for mechanical engineers or molecular modeling for biochemists workflows are run on either pools or clusters depending on the need of the workflow there are several demonstration and template workflows available in the pw marketplace see navigating the platform  marketplace for more information system emails the pw platform sends notifications to users via email our system can be configured to send daily reports regarding cloud resource usage additionally all group members will receive emails when usage exceeds the groups budget allocation thresholds of 85 90 95 and 995 your email service provider may send pw notifications to your junk or spam folder we advise that you periodically check that folder for system messages for most email service providers you can add our system email address noreplyparallelworkscom to your safe senders list or address book to redirect pw emails to your inbox for gmail users you can also use their label service to redirect pw platform emails further instructions for that process can be found here about this guide we constantly update the platform adding features to make it easier to complete largescale projects our documentation is a work in progress the following instructions and information will be updated regularly as we work to improve our platform and our users experience we would love to hear your feedback feel free to share your requests for additional features and thoughts about the platform at feedbackparallelworkscom',\n",
       " 'sidebar_position 2 label navigating the platform navigating the platform this section introduces the major features of the platform to help new users get oriented logging in when you navigate to cloudparallelworks youll see the login page the url you use may be different from cloudparallelworks depending on your organization and whether you use an onpremise or dedicated instance of the platform when you log in the password box will only appear after you enter your username or email address and click next if you enter your username and see the error message username or email not found please reach out to us at supportparallelworkscom for assistance home page when you log in to the pw platform youll see the compute tab by default youll regularly interact with the following platform features the compute tab where you can monitor your resources and workflows the resources tab where you can create and manage resources the workflows tab where you can add and manage workflows the user workspace panel labeled explorer pw where you can access a terminal interface and files for any jobs that youve run on the platform the user menu which gives you access to your account settings and the pw marketplace compute the compute tab serves as your primary activity monitor on the pw platform you can select your favorited workflows adjust resource requirements and view past run results from this page there are four main boxes in this tab favorite workflows where you can store your favorited workflows for easy access workflow monitor where you can keep track of current and past workflow runs cancel runs and run workflows again resource monitor where you can see how many nodes are active and how long theyve been running computing resources where you can stop and start your resources or configure them by clicking the gear icon all of these boxes are expanded by default you can collapse a box by clicking its title or the arrow next to the title you can also collapse individual items in computing resources by clicking on their titles resources in the resources tab you can access your current computing resources and add new ones you can also manage your existing resources by favoriting duplicating editing deleting or sharing them with other users in your organization for more information on how to add and configure new resources see creating clusters and configuring clusters workflows the workflows tab displays the preconfigured workflow tools and templates you can run on the platform any workflows you build or add from the marketplace will appear here automatically you can also manage your existing workflows by favoriting duplicating editing deleting or sharing them with other users in your organization user workspace ide the explorer pw panel on the right side of the screen is your user workspace also known as the integrated development environment ide if you click the ide icon  the panel will expand to fit your screen showing a terminal pane at the bottom of the page by default the ide is a powerful tool allowing you to view job output and error files run code and debug workflows our ide is based on theia when you use a terminal in the ide it runs commands much like terminal on macos or command prompt on windows you can hide the ide completely by clicking the arrow icon that appears in the bottom right corner of your screen when the ide is collapsed marketplace the marketplace page is where you can select preconfigured workflows for your projects you can navigate here by clicking on your username then selecting marketplace from the dropdown menu you can sort these preconfigured workflows by using either the search bar or the category pane by default all items under category are collapsed but will expand when you click them account the account page is where you can manage your login information cloud snapshots and cloud accounts you can navigate here by clicking on your username then selecting account from the dropdown menu the sections of your account page are detailed below profile here you can change your password as well as your display name by typing in the name field your username and email are locked to what was assigned when your account was created api key here you can access your api key youll use your api key any time you need to interact with the api such as for automation tasks cloud snapshots here you can create and access cloud snapshots when you create a cloud snapshot a temporary virtual machine vm executes a script the system takes a snapshot of that vm which it uses to create an image you can access this image in any dropdown menu where its possible to select machine images for example if your organization uses an application that takes an hour to install you can create a cloud snapshot of your computer after installation then use that snapshot to avoid the installation process every time a user needs that application for more information see working with cloud snapshots cloud accounts here you can connect your pw account to existing cloud accounts from aws google and azure or use a private ssh key from an existing resource this feature is useful if you need to connect to a preconfigured resource either from a cloud account or from another user in your organization for more information see linking cloud accounts coming soon',\n",
       " 'sidebar_position 7 restarting your workspace your user workspace is your dedicated environment for starting clusters running workflows and accessing your data on the platform each users workspace is separate from each other so the work you do on the platform will never affect another users work this page explains how to restart your user workspace which is useful if youre experiencing issues like a cluster that wont start or a workflow that wont run info note all running clusters and jobs will be disrupted if you restart your workspace  navigate to your account settings username  account in your profile settings click restart workspace a dialog box will appear with the message are you sure you want to restart your workspace click restart after the workspace has restarted youll see the message user workspace killed info troubleshooting if you restarted your workspace because you were experiencing errors and they arent resolved after restarting please contact us or your pw platform administrator ',\n",
       " 'sidebar_position 3 sidebar_label attaching storage title  attaching storage after youve created and configured a storage option you can attach it to one of your clusters navigate your clusters configuration page click the definition tab in the attached storages section at the bottom of the page click  add attached storage two new parameters will appear storage and mount point use the storage dropdown menu to select which storage option to attach to this cluster please note that only storage options that match your clusters csp will be shown for example an aws cluster will only show aws fsx for lustre or aws elastic file system use the mount point field to enter the directory where the storage will be mounted in the clusters controller and compute nodes please note that the mount point should be an absolute path info note you can add or remove persistent storage options while a cluster is running you cannot do so with ephemeral storages  verifying storage mounts after youve logged in to your cluster you can run the following command to verify that the storage is mounted correctly bash df h after you enter the command you should see the storage mounted at the mount point you defined mounts are updated every 45 seconds if you very recently attached a storage option to a cluster there may be a short delay before you see your storage in the mount list',\n",
       " 'title  about storage and flexible file systems you can manage your storage on the pw platform with our newest feature flexible file systems previously we had only one storage option lustre which you could configure inside the cluster definition page now we offer several other storage options along with lustre which can all be configured in the storage tab the lustre definition settings on the cluster configuration page have been replaced with a section called attached storages with this latest update you can also configure more than one file system per cluster before these changes clusters could only be configured with one storage definition at a time now you can attach multiple file systems at once including lustre and google or aws bucket storage about storage types when creating storage options youll choose whether your storage is ephemeral or persistent ephemeral storage is created and destroyed with a cluster this type of storage is provisioned when you start the cluster its attached to and its destroyed when you stop the cluster ephemeral storage options do not have a power button and they wont appear in the storage resources box on the the compute page persistent storage is created and destroyed independently if you want to destroy a persistent storage option you can do so from the storage page by clicking the power button persistent storage can be attached to multiple clusters at this time bucket storage options cannot be made ephemeral about storage provisioning logs for persistent storage options you can see the creation and deletion logs in this tab all logs for current and previous sessions will be displayed if a persistent storage option is active youll see all the clusters that the storage is attached to for more information please see sessions in configuring storage ephemeral storage options do not have a sessions page instead you can see their creation logs by navigating to resources  resourcename  sessions  logs  storages for more information please see sessions in configuring clusters about buckets typically users would have to use a cloud service providers cli to upload or retrieve data from a bucket with our new file system feature buckets are instead mounted as a file system this way you can interact with a bucket as if its a directory rather than using cli commands',\n",
       " 'sidebar_position 1 sidebar_label creating storage title  import  bsfilleyefill  from reacticonsbs creating storage navigate to the storage tab and click  add storage on the next page there are five storage options to choose from aws fsx for lustre lustre on google lustre on azure aws s3 bucket google cloud bucket select a filesystem and enter a storage name the short description tags and thumbnail are all optional descriptors if you dont upload a thumbnail image the storages icon will default to the icon of the option youve chosen in storage type select whether your storage will be ephemeral or persistent please note that cloud object stores aws s3 buckets and google cloud buckets cannot be ephemeral click add storage next youll see the default settings page for the new storage please see configuring storage for the next steps info note after you create a persistent storage option it will appear in the storage resources box in the compute tab you can hide storage options from the compute tab by clicking the eye icon in the storage tab however ephemeral storage options will not appear in the compute tab because they cannot be started independently they must be attached to a cluster where the storage will be created started and deleted along with the cluster for more information please see about storage types  which type of storage should i use lustre is a high inputoutput file system so we recommend using lustre storage options only when youre completing compute work that needs that type of performance the other storage options are equivalent to contrib and work well for general use',\n",
       " 'sidebar_position 2 sidebar_label configuring storage title  accessing storage configuration settings youll see the storage configuration page immediately after creating any storage option you can also access configuration settings from the storage tab click the name of any existing storage to configure it about the storage configuration page when you navigate to the storage configuration page there are five tabs for customization sessions by default youll see the sessions tab when you navigate to storage settings this tab shows your previous sessions for using the storage as well as provision and deletion logs info about storage provisioning logs for persistent storage options you can see the creation and deletion logs in this tab all logs for current and previous sessions will be displayed if a persistent storage option is active youll see all the clusters that the storage is attached to ephemeral storage options do not have a sessions page instead you can see their creation logs by navigating to resources  resourcename  sessions  logs  storages for more information about persistent and ephemeral storage please see about storage types  definition here you can adjust the configuration parameters of your storage for more information see general settings below _ json this tab shows the code version of your storage configuration settings here you can manually adjust the parameters seen in the definition tab properties this tab shows the name that you entered when the storage was created here you can change the name and upload a new thumbnail for the cluster sharing this tab lets you share your storage option with other users in your organization who are assigned to the same group general settings storage options have these settings in the definition tab of the configuration page cloud infrastructure use this dropdown menu to choose your infrastructure which determines which region your storage will be created in group use this dropdown menu to select the group name that your organization uses to allocate costs this menu is especially important if your organization uses multiple groups if youre not sure which group to select you can contact us or your organizations pw platform administrator lustre options aws fsx for lustre the configuration parameters below are exclusive to aws fsx for lustre availability zone use this dropdown menu to select the availability zone that your infrastructure will be deployed in an availability zone refers to an isolated location inside a region we recommend that your storage availability zone matches the availability zone of the cluster youre pairing the storage with storage capacity gb use this field to enter the total capacity of your storage this field is set to 1200 by default 1200 is the minimum amount of storage and must be increased in increments of 2400 please note that altering the storage size will affect your estimated hourly cost file system deployment use this dropdown menu to select which type of file system your storage will be deployed as currently the options are scratch and persistent scratch file systems are meant for shorterterm workloads they provide a higher throughput per tib of storage capacity if a scratch file system fails your data is not replicated persistent file systems are meant for longterm workloads if this file system fails your data will automatically replicate in the same availability zone file system compression use this dropdown menu to select whether your file system will be compressed currently the options are lz4 and none lz4 compresses data when writing to lustre when reading from lustre lz4 decompresses data while minimally impacting performance using lz4 can improve read and write performance as well as reduce storage capacity s3 import path optional use this field to enter an s3 bucket path to import data from the format for this field is s3bucketname s3 export path optional use this field to enter an s3 bucket path to export data to the format for this field is s3bucketname lustre options lustre on google the configuration parameters below are exclusive to lustre on google region use this dropdown menu to select the region that your storage will be deployed into a region represents a geographic area zone use this dropdown menu to select the zone to use your storage a zone refers to an isolated location inside a region we recommend that your storage zone matches the zone of the cluster youre pairing the storage with mds nodes use this field to enter the number of nodes on your storages mds this field is set to 1 by default and will be sufficient for most workloads info about mds mds stands for metadata service in lustre file systems the mds manages the namespace hierarchy records the layout of files and handles object allocation on object storage targets osts mds fields largely affect data transfer speeds  mds machine type use this dropdown menu to select the machine type for your mds nodes the machine type determines the cpus and amount of memory available certain machine types may also have specialty hardware such as gpus or lowlatency networking options please note that altering the mds machine type may affect your estimated hourly cost mds boot disk type use this dropdown menu to select the type of disk your mds nodes will use currently the options are localssd pdbalanced pdstandard and pdssd generally speaking the ssd options will be faster than balanced options and balanced options will be faster than standard options please note that altering the boot disk type will slightly affect your estimated hourly cost mds boot disk size gb use this field to enter the total capacity of your mds boot disk storage this field is set to 20 by default please note that altering the boot disk size will slightly affect your estimated hourly cost mdt disk type use this dropdown menu to select the type of disk your mdt nodes will use currently the options are localssd pdbalanced pdstandard and pdssd generally speaking the ssd options will be faster than balanced options and balanced options will be faster than standard options please note that altering the boot disk type will slightly affect your estimated hourly cost info about mdt mdt stands for metadata target metadata content is stored on mdts mdt fields largely affect data transfer speeds  mdt disk size gb optional use this field to enter the total capacity of your mdt boot disk storage please note that altering the boot disk size will slightly affect your estimated hourly cost oss nodes use this field to enter the number of nodes on your storages oss this field is set to 2 by default changing the number of oss disk nodes changes your storages capacity and overall throughput if youre interested in tuning your lustre file system this parameter as well as oss disk type will most strongly affect your storages performance info about oss oss stands for object storage servers in lustre file systems oss provide the bulk data storage for all file content  oss machine type use this dropdown menu to select the machine type for your oss nodes the machine type determines the cpus and amount of memory available certain machine types may also have specialty hardware such as gpus or lowlatency networking options please note that altering the oss machine type may affect your estimated hourly cost oss boot disk type use this dropdown menu to select the type of disk your oss nodes will use currently the options are localssd pdbalanced pdstandard and pdssd generally speaking the ssd options will be faster than balanced options and balanced options will be faster than standard options please note that altering the boot disk type will slightly affect your estimated hourly cost oss boot disk size gb use this field to enter the total capacity of your oss boot disk storage this field is set to 20 by default please note that altering the boot disk size will slightly affect your estimated hourly cost ost disk type use this dropdown menu to select the type of disk for your ost nodes currently the options are localssd pdbalanced pdstandard and pdssd generally speaking the ssd options will be faster than balanced options and balanced options will be faster than standard options please note that altering the ost disk type will affect your estimated hourly cost info about ost ost stands for object storage target an ost is a set of storage volumes that oss provides access to  ost disk size gb use this field to enter the total capacity of your ost boot disk storage this field is set to 1500 by default please note that altering the boot disk size will slightly affect your estimated hourly cost lustre version use this field to enter the version of lustre software that your storage will use this field is set to latestrelease by default and we recommend using this setting for the best performance lustre image use this dropdown menu to select the lustre image that your storage will use the image has prepackaged software that our engineers have installed to maximize performance we recommend selecting latest for the best performance gvnic use this toggle button to enable google virtual network interface card gvnic which supports higher network bandwidths from 50100 gbps this parameter affects both mds and oss nodes this storage feature can be toggled independently of the gvnic option on your cluster your clusters configuration will not be affected for more information see the google documentation on gvnic tier 1 use this toggle button to enable tier_1 which increases maximum egress bandwidth upload speed to 50100 gps if tier_1 is off the egress bandwidth will range from 1032 gbps this parameter affects both mds and oss nodes please note that tier1 is only supported if gvnic is also active if you try to start tier1 by itself the pw platform will display the error message tier_1 is only supported if gvnic is on for more information see the google documentation on tier_1 lustre options lustre on azure the configuration parameters below are exclusive to lustre on azure region this field identifies which region the storage will be deployed in please note that this field is locked because the region is determined by which cloud infrastructure is selected lustre image use this dropdown menu to select the lustre image that your storage will use the image has prepackaged software that our engineers have installed to maximize performance we recommend selecting latest for the best performance mds nodes use this field to enter the number of nodes on your storages mds this field is set to 1 by default and will be sufficient for most workloads info about mds mds stands for metadata service in lustre file systems the mds manages the namespace hierarchy records the layout of files and handles object allocation on object storage targets osts mds fields largely affect data transfer speeds  mds machine type use this dropdown menu to select the machine type for your mds nodes the machine type determines the cpus and amount of memory available certain machine types may also have specialty hardware such as gpus or lowlatency networking options please note that altering the mds machine type may affect your estimated hourly cost mds boot disk type use this dropdown menu to select the type of disk your mds nodes will use currently the options are localssd pdbalanced pdstandard and pdssd generally speaking the ssd options will be faster than balanced options and balanced options will be faster than standard options please note that altering the boot disk type will slightly affect your estimated hourly cost mds boot disk size use this field to enter the total capacity of your mds boot disk storage this field is set to 20 by default please note that altering the boot disk size will slightly affect your estimated hourly cost oss nodes use this field to enter the number of nodes on your storages oss this field is set to 2 by default changing the number of oss disk nodes changes your storages capacity and overall throughput if youre interested in tuning your lustre file system this parameter as well as oss disk type will most strongly affect your storages performance info about oss oss stands for object storage servers in lustre file systems oss provide the bulk data storage for all file content  oss machine type use this dropdown menu to select the machine type for your oss nodes the machine type determines the cpus and amount of memory available certain machine types may also have specialty hardware such as gpus or lowlatency networking options please note that altering the oss machine type may affect your estimated hourly cost oss boot disk type use this dropdown menu to select the type of disk your oss nodes will use currently the options are localssd pdbalanced pdstandard and pdssd generally speaking the ssd options will be faster than balanced options and balanced options will be faster than standard options please note that altering the boot disk type will slightly affect your estimated hourly cost oss boot disk size use this field to enter the total capacity of your oss boot disk storage this field is set to 20 by default please note that altering the boot disk size will slightly affect your estimated hourly cost accelerated networking use this toggle button to enable accelerated networking which improves networking performance for large workloads on multiple cloud clusters for more information see the azure documentation on accelerated networking cloud object stores aws s3 bucket the configuration parameters for aws s3 buckets are explained below region use this dropdown menu to select the region that your storage will be deployed into a region represents a geographic area cloud object stores google cloud bucket the configuration parameters for google cloud buckets are explained below region use this dropdown menu to select the region that your storage will be deployed into a region represents a geographic area',\n",
       " 'sidebar_position 2 transferring data tofrom aws s3 storage working with aws cli to transfer data tofrom s3 bucket storage youll use the aws command line interface cli because the aws cli is preinstalled on aws clusters in the pw platform you can enter commands directly into the ide after logging in to the controller of an active aws cluster if youre transferring data between s3 buckets and a folder an onpremise cluster or a remote device youll likely need to install the aws cli first check for aws cli open a terminal or command line and navigate to your datas destination enter which aws if the aws cli is installed youll see a message that shows its location such as usrlocalbinaws if the aws cli is not installed youll see a message such as usrbinwhich no aws or aws not found install aws cli if you need to install the aws cli we recommend following the aws installation guide which includes osspecific instructions for linux macos and windows as well as troubleshooting tips transferring your data export your aws credentials in your terminal enter export aws_access_key_id_____ with your aws access key id in the blank space enter export aws_secret_access_key_____ with your aws access key id in the blank space info note please be sure to include the quotation marks on both ends of your key ids there are characters inside aws key ids that without quotation marks systems will try to read as commands  validate your aws credentials in your terminal enter aws sts getcalleridentity to check that the system correctly registered your aws credentials if your login was successful youll see your aws userid account and arn bash  userid abcd1e2fg3h4ijklmnopq account 012345678901 arn arnawsiam 012345678901useradmin  if your login was not successful enter your aws access keys again with the export commands above you can also configure your login credentials manually with aws configure for more information about that process see the aws documentation on environment variables and configuration files list files in s3 in your terminal enter aws s3 ls s3bucket_name to display the files in your bucket for this guide we used a small text file named testtxt so our command returned this message bash demopwuserdemopwclouddatatransfer aws s3 ls s3clouddatatest 20230208 163756 28 testtxt transfer a file from s3 in your terminal enter aws s3 cp s3bucket_namefile_name  to download a file from s3 storage to your current directory youll see this message bash demopwuserdemopwclouddatatransfer aws s3 cp s3clouddatatesttesttxt  download s3clouddatatesttesttxt to testtxt to download a file from s3 storage to a specific directory enter its name after  with the aws s3 cp command we used the storage directory in this example bash demopwuserdemopwclouddatatransfer aws s3 cp s3clouddatatesttesttxt storage download s3clouddatatesttesttxt to storage transfer a file to s3 in your terminal enter aws s3 cp file_name s3bucket_name to transfer a file to your s3 bucket youll see this message bash demopwuserdemopwclouddatatransfer aws s3 cp test_uploadtxt s3clouddatatest upload test_uploadtxt to s3clouddatatesttest_uploadtxt you can check your s3 files with aws s3 ls s3bucket_name bash demopwuserdemopwclouddatatransfer aws s3 ls s3clouddatatest 20230208 163756 28 testtxt 20230208 171924 28 test_uploadtxt delete a file from s3 in your terminal enter aws s3 rm s3bucket_namefile_name to delete a file youll see this message bash demopwuserdemopwclouddatatransfer aws s3 rm s3clouddatatesttest_uploadtxt delete s3clouddatatesttest_uploadtxt you can check your s3 files with aws s3 ls s3bucket_name bash demopwuserdemopwclouddatatransfer aws s3 ls s3clouddatatest 20230208 163756 28 testtxt',\n",
       " 'sidebar_position 1 label creating clusters creating clusters any work you do on the pw platform will need to be completed on a resource if you dont have any preconfigured resources that fit your needs for the project at hand you can create a new one navigate to the resources tab and select  add resource now you can select the type of resource you need from the available elastic clusters once you choose your type of resource you can create a cluster on a specific cloud service provider csp for example if you want to create an elastic cluster you can do so with resources from aws google or azure when creating a cluster you must enter a pool name the display name short description tags and thumbnail are all optional descriptors if you leave display name blank the cluster will default to the pool name text if you dont upload a thumbnail image the clusters icon will default to the icon of the csp youve chosen after youve entered information into all the fields select add resource your resource creation will be confirmed on the next page with the message resource created you can configure your resource from this page for more information on configuring clusters generally or what you need to configure clusters on specific csps see configuring clusters your new cluster will also appear in the computing resources box in the compute tab which type of resource should i use if youre creating a new resource an elastic cluster is typically the best choice users who are familiar with slurm will be more comfortable using elastic clusters instead of elastic pools additionally newer pw workflows run exclusively on elastic clusters for these reasons we consider elastic pools to be a legacy feature and discourage users from choosing them to create new resources the csp you choose depends on your organization workflow needs and whether you already have a cloud account from a specific csp otherwise any elastic cluster is a good choice to start with how should i configure my resource if youre simply testing resources or if your organization has not provided specific configuration settings for your project we recommend using the default configuration settings for more information see configuring clusters  default pool configuration',\n",
       " 'sidebar_position 3 label starting and stopping clusters starting and stopping clusters starting clusters navigate to the computing resources box in the compute tab click the power button  while the cluster starts the power button will flash green and the requested status bubble will turn yellow it may take up to 15 minutes for an aws cluster to start and roughly 5 minutes for a google cluster to start when your cluster is online both the power button and the active bubble will turn green now your cluster is ready to run workflows stopping clusters when your jobs are finished or youre ready to turn off any running clusters click the power button  a dialog box will appear with the message are you sure you want to turn off cluster name click turn off to stop the cluster when you stop a cluster all data in lustre and the local file system will be lost only the data in the object storage aws s3 buckets gcs buckets or azure blob containers and contrib will remain its important to copy any data youd like to keep to object storage or to a remote location info note its essential to turn off the cluster when youve finished your work clusters that run unmonitored continue to accrue additional charges which will be subtracted from your organizations allotment ',\n",
       " 'sidebar_position 2 label configuring clusters configuring clusters most users on the pw platform will work exclusively with elastic clusters these clusters are made up of a controller node and compute nodes with the controller delegating tasks to the compute nodes clusters have several adjustable parameters for both controller and compute nodes such as compute instance types and node count additionally compute nodes are grouped together in partitions which have their own settings for more information see partition settings below the pw platform also supports an optional parallel file system lustre for more information on setting up lustre for your account see storage coming soon accessing configuration settings you can access a resources configuration settings from the compute tab navigate to the computing resources box and click the gear icon for the resource you want to configure alternatively you can navigate to the resources tab and click the name of the resource you want to configure about the resource configuration page when you navigate to a clusters configuration settings there are four tabs for customization sessions by default youll see the sessions tab when you navigate to configuration settings this tab shows your previous cluster sessions well as provisioning and deletion logs info about storage logs in the sessions box of this tab youll also be able to see sessions for any attached ephemeral storage options if multiple ephemeral storage options are attached to the cluster youll see a dropdown to select when ephemeral storage logs youd like to see the deletion logs for ephemeral storage options are combined with the cluster deletion logs for more information please see about storage types  definition here you can adjust your clusters parameters for more information see general settings below _ json this tab shows the code version of your resources configuration settings here you can manually adjust the parameters seen in the definition tab properties this tab shows the resource name description display name and tags that were entered when the resource was created here you can adjust those settings and upload a new thumbnail for the cluster sharing this tab lets you share your resource with other users in your organization who are assigned to the same group please note that your group names will be specific to your organization for more information see group below general settings clusters will typically have these settings in the definition tab of the configuration page if youre using an existing onpremise cluster see existing cluster settings below resource account use this dropdown menu to select the account that your organization uses for a specific cloud service provider by default this menu will show the resource account that your organization has selected for that type of cluster for example the screenshot above shows a google cluster and resource account was automatically populated with the pworks gcp account group use this dropdown menu to select the group name that your organization uses to allocate costs this menu is especially important if your organization is running multiple groups simultaneously if youre not sure which group to select you can contact us or your organizations pw platform administrator multi user use this toggle button to automatically create a home directory for all users in the selected group this option is different from the sharing tab which allows sharing the resource definition with other users in your organization access public key use this box to add an ssh key so you can access the cluster from a remote device like your local laptop please note that keys must be in openssh format and you should only enter a public key not a private key for more information on how to use a public key see logging in to the controller script settings optionally you can set scripts to execute when you start a cluster user bootstrap use this box to set a script that executes once a controller node has started for example you can set files to automatically move into a specific folder health checks use this box to set a script that runs a health check on a controller node when the script is done running youll see any error codes in red or an exit code of 0 in green if there are no errors for more information see health checks coming soon controller settings these settings define the configuration for the controller node such as region instance type and os image some settings will differ depending on which type of resource youre using for more information see cspspecific settings below region use this dropdown menu to select the region that your cluster will deploy computing resources into a region represents a geographic area zone use this dropdown menu to select the zone to use for the controller a zone refers to an isolated location inside a region info note azure clusters do not have a zone menu  instance type use this dropdown menu to select the instance type of the controller the instance type determines the cpus and amount of memory available on the machine certain instance types may also have specialty hardware such as gpus or lowlatency networking options image use this dropdown menu to select the operating system os image for the clusters controller node we recommend using the latest version because this will ensure you have the most uptodate software on your cluster the latest image version includes os updates and software required to connect to the pw platform image disk name fixed if your organization uses a snapshot of a disk this field will identify that snapshot for example your organization may have specific applications that users need to complete their work your administrator may create a snapshot of a disk to make those apps available to users whenever a cluster starts and the name of that snapshot would be in image disk name please note that if you make any changes to this directory while on the cluster those changes will be lost when you turn the cluster off your changes will not affect the snapshot or other users work image disks use this field to enter the number of image disks youll need for the cluster typically youll either enter 1 if you need the directory from image disk name or 0 if you would like to disable the image disk image disk size gb use this field to enter the amount of storage on your image disk the size depends on the size of the snapshot and should be provided by your organizations administrator partition settings you can create partitions in clusters to send your work to differently configured sets of worker nodes partitions are especially useful if youre working on a project that needs more or fewer nodes for specific tasks for example if you were running a simulation model and only a small dataset required twice the amount of gpu power to render properly info note you must have at least one partition in your cluster  if you click  add partition a list of new settings will expand typically a partition will have the following configuration options some settings will differ depending on which type of resource youre using for more information see cspspecific settings below name use this box to name your partition be sure to use a unique name for each partition you create your partition should never be named default instance type use this dropdown menu to select the configuration of the partition these options work in the same way that the controller instance types do max nodes use this field to enter the max number of nodes in a partition default use this toggle button to specify whether a partition is the default location for running jobs for more information on running jobs on specific partitions see submitting jobs info default partition this feature is important if you create multiple partitions if you only create one partition it will automatically be set to default and cannot be changed as shown in the screenshot above  spot use this toggle button to specify whether a partition is a spot instance spot instances can be cost effective because they make use of resources that are already available but currently unused however spot instances can be disrupted because another user can take over that available resource at any time for this reason we recommend using spot instances at your own risk elastic image use this dropdown menu to select the operating system image for the partition we recommend using the latest version zone use this dropdown menu to select the zone within your selected region you can configure your partition to run in a different zone than your controller node selecting different zones on multiple partitions increases the chance provisioned resources will be available from the cloud provider there is a performance penalty if compute nodes need to communicate across zones slurm settings the pw platform uses slurm to manage jobs on controller and compute nodes the settings below determine how slurm behaves for your clusters nodes please note that numerical values you enter in these fields are measured in seconds suspend time use this field to set how long slurm will wait before shutting down idle nodes this field is set to 300 by default resume timeout use this field to set the maximum amount of time slurm will try to start nodes if the nodes dont start by the end of the set time slurm will end the initialization attempt this field is set to 1200 by default suspend timeout use this field to set how long slurm will wait to make nodes available again after shutting them down this field is set to 300 by default return to service use this dropdown menu to select when down nodes are returned to service the non responsive option means that down nodes will become available only if they were set to down because they were nonresponsive the any reason option means that down nodes will become available if they were set to down for any reason including low memory an unexpected reboot or being nonresponsive this field is set to non responsive by default cspspecific settings each cloud service provider csp builds and configures their resources differently clusters on the pw platform have settings that correspond to each csps model of cloud services the cspspecific parameters are outlined below please note that these cspspecific settings will also appear as options inside the partition settings on clusters aws efa use this toggle button to enable elastic fabric adapter efa which improves interinstance network performance efa is useful if you need to scale hpc or machinelearning applications to thousands of cpus or gpus please note that efa is not supported on all instance types for more information and a list of supported instance types see the aws documentation on efa azure export filesystem use this field to enter the name of a network file system nfs which is an existing system on an external device thats available for read andor write access on your cluster if you want to set up an nfs please contact us or your pw platform administrator nfs size use this field to enter the size of your nfs please note that the values for nfs size and image disk size must be the same accelerated networking use this toggle button to enable accelerated networking which improves networking performance for large workloads on multiple cloud clusters for more information see the azure documentation on accelerated networking google gvnic use this toggle button to enable google virtual network interface card gvnic which supports higher network bandwidths from 50100 gbps please note that gvnic is not supported on all instance types for more information and a list of supported instance types see the google documentation on gvnic tier_1 use this toggle button to enable tier_1 which increases maximum egress bandwidth upload speed to 50100 gps depending on the size of the instance if tier_1 is off the egress bandwidth will range from 1032 gbps please note that tier1 is only supported if gvnic is also active if you try to start tier1 by itself the pw platform will display the error message tier_1 is only supported if gvnic is on for more information see the google documentation on tier_1 migrate on maintenance this toggle button enables live migration whenever the virtual machines host undergoes maintenance meaning that google will migrate the virtual machine to another host without any downtime please note that gpu and spot instances cannot be live migrated when supported we recommend turning this feature on for more information see the google documentation on live migration existing cluster settings typically when you create an existing cluster youll be connecting to an onpremise cluster associated with your organization the settings that are specific to this type of cluster are outlined below if youre unsure what to choose for these options contact your organizations pw platform administrator general settings for existing clusters resource account use this dropdown menu to select how the pw platform will connect to the existing cluster the default options means that the platform will try to ssh to the cluster by using only your pw accounts ssh key which is stored in sshpw_id_rsa for more information about your pw ssh key see our documentation the pin or password only option creates a dialog box when you start the cluster where you can enter the password for your user account the account you define in username this options means that the platform will connect to the cluster using only these credentials multi factor use this toggle button if youre connecting to a cluster that has mfa enabled when you turn on the resource and mfa is enabled a dialog box will appear prompting you to enter your mfa code this button is different from the options in resource account if you toggle mfa on the platform will connect to the existing cluster using both the ssh key in your pw account and your mfa credentials jump node use this toggle button if youre connecting to a cluster that has a jump node enabled a jump nodealso called a host node bastion node or login nodeis a highsecurity server that allows a user to access a private machine or network if you enable this feature two new fields will appear for jump node user and jump node host your organization will have these credentials if you need them group use this dropdown menu to select the group name that your organization uses to allocate costs this menu is especially important if your organization uses multiple groups if youre not sure which group to select you can contact us or your organizations pw platform administrator cluster configuration settings for existing clusters username use this field to enter the username assigned to you for this cluster info username substitution on existing clusters you can enter __user__ into any box and the pw platform will automatically substitute your username for that field for example if your username is jdoe the pw platform will automatically substitute __user__ for jdoe in the working directory field  cluster login node use this field to enter the ip address or host name of the cluster working directory use this field to enter the directory youll be accessing while completing work on this cluster by default this field is set to homeslurmusername max workers use this field to enter the maximum number of compute nodes you need to complete your work internal ipnetwork name optional use this field to specify the internal ip address or network name that the compute nodes use to communicate with the controller nodes you only have to use this feature if your organization has configured the clusters compute nodes to send information to an ip address other than the controllers default ip address you can run the command ifconfig on a cluster after logging in to the controller to see all of the available ip addresses scheduler type use this dropdown menu to select the type of job scheduler the cluster uses currently the existing cluster resource type supports slurm and pbs default configuration if youre simply testing resources or if your organization has not provided specific configuration settings for your group we recommend using the default configuration settings because they allow resources to run most projects with optimal performance to set or reset a resource to the default pool configuration navigate to the resources tab and click the name of the resource you want to edit the configuration page will open click the restore configuration button after you click restore configuration a dialog box will appear with the message restore configuration to default values from the dropdown menu in the dialog box click the configuration labeled benchmark click restore click save resource info existing clusters existing clusters do not have a restore configuration button  info extra lustre expense when you use the default configuration settings the cluster will automatically be equipped with a lustre file system lustre is powerful but generally increases costs significantly on google and azure clusters please feel free to turn lustre off if you dont need it particularly if youre transferring small files or simply testing a resource ',\n",
       " 'sidebar_position 5 submitting jobs via slurm info about jobs there are two ways you can submit jobs to a cluster by using workflows or through any terminal or commandline interface for the workflows option please see running workflows  after youve started a cluster log in to the controller with your preferred method the quickest way to submit a job is to transfer your files to the cluster then run the command sbatch in this example we submitted the file demo_test1sbatch with sbatch shell demodemocluster60  ls demo_test1sbatch demodemocluster60  sbatch demo_test1sbatch submitted batch job 2 after submitting a job you can watch its progress with the command watch squeue which will update every two seconds with the jobs status in the st column shell every 20s squeue jobid partition name user st time nodes nodelistreason 4 testpart test demo cf 008 2 demodemocluster00060100010002  you can also use watch sinfoechosqueue if you want to see general cluster information in addition to your jobs progress shell every 20s sinfo echo squeue partition avail timelimit nodes state nodelist testpartition1 up infinite 2 mix demodemocluster00060100010002 testpartition1 up infinite 3 idle demodemocluster00060100030005 testpartition2 up infinite 5 idle demodemocluster00060200010005 jobid partition name user st time nodes nodelistreason 4 testpart test demo cf 026 2 demodemocluster00060100010002  when using watch squeue or watch sinfoechosqueue the st column will show cf while the nodes configure all of the rows beneath jobid will clear when your job is finished shell every 20s sinfo echo squeue partition avail timelimit nodes state nodelist testpartition1 up infinite 2 idle demodemocluster00060100010002 testpartition1 up infinite 3 idle demodemocluster00060100030005 testpartition2 up infinite 5 idle demodemocluster00060200010005 jobid partition name user st time nodes nodelistreason  once the job is finished you can check its output with cat file_name our file demo_test1sbatch inlcuded instructions to send our completed jobs data to an stdout file and any errors to an stderr file shell demodemocluster60  ls demo_test1sbatch stderr stdout demodemocluster60  cat stderr demodemocluster60  cat stdout demodemocluster0006010001 demodemocluster0006010001 demodemocluster0006010002 demodemocluster0006010002 using cat stderr didnt return anything because the job executed without errors common slurm commands this section gives a quick overview of the commands youll use most often when interacting with clusters you can use any of these commands in any terminal after logging in to a controller node because the pw platform uses slurm to manage jobs you can use any of their system commands for an extensive list of those options see slurms command guide you can also enter man in front of any command such as man sacct to see its description and a list of other available commands in slurms virtual manual info about job ids when we say job id in this section we mean the job id that slurm assigns to your work which will appear when running many of these commands id numbers in the worflow monitor and the jobs folder on the pw platform act as a separate identifier to help us track how many jobs weve ever run on the platform using any of the commands in this section will generate a new slurm job id  info about fault tolerance fault tolerance is defined by how well an infrastructure remains functional or online even when there are service disruptions because of outages or natural disasters on the pw platform cluster deletions are queuebased for fault tolerance the cluster startup process has no retries for fault tolerance but the logs are visible so users can see any problems that occur for compute node startup requests fault tolerance is implemented with retries via slurm by default there is a new startup attempt approximately every 20 minutes  job management salloc salloc retrieves resources for your job without executing any tasks using this command retrieves resources before you need them by signaling the system to reserve a specified number of nodes for example salloc n 2 will reserve two compute nodes for a total of three nodes including the controller salloc is useful if youre sharing a cluster with other users in your organization using this command means that once a job is finished the allocated nodes will remain on reserve for your use until you disconnect from the cluster meaning that your wait times will be shorter because another user cannot take control of your allocated nodes so you wont have to wait for more nodes to become available or wait for them to start once theyre available sbatch sbatch submits a job script that will execute later you can also configure nodes with sbatch by adding these options ntaskspernode to specify the number of cpus t to specify the maximum amount of time you want these resources to run with the format of 000 for hours minutes and seconds for example sbatch demo_test1sbatch ntaskspernode 5 t 300 would run the file demo_test1sbatch and request 5 cpus for 3 hours of maximum run time srun srun executes a job script you can use the same options from salloc and sbatch with srun n to specify the number of nodes ntaskspernode to specify the number of cpus t to specify the maximum amount of time you want these resources to run for example srun n 1 pty bash would request 1 compute node and open a pseudoterminal creating an interactive commandline session scancel scancel paired with a job id ends a pending or running job or job step for example shell demodemocluster60  sbatch demo_test1sbatch submitted batch job 6 demodemocluster60  scancel scancel error no job identification provided demodemocluster60  scancel 6 if you cancel a job it will disappear from your queue cluster management sinfo sinfo shows information about the nodes and partitions youre using by default sinfo displays partition names availability time limit the number of nodes state and the nodes id number which is displayed as usernamedemocluster00019100010005 please note that if you enter sinfo without setting up partitions youll receive the error message slurm_load_partitions unable to contact slurm controller connect failure squeue squeue shows a list of running and pending jobs by default squeue shows job id number partition username job status number of nodes and node names for all queued and running jobs you can also use these commands to adjust squeues output user to see only one users jobs such as useryourpwusername long to show nonabbreviated information and add the field timelimit start to estimate a jobs start time troubleshooting sacct sacct shows a summary of users as well as completed and running jobs using this command will display a table with a jobs id number name partition status exit code whose account its running on and how many cpus its using for troubleshooting purposes the state and exitcode fields from running sacct are especially useful for determining whether a node has failed and if so why if you reach out to us for help one of our support engineers may ask you for the information you see after running sacct scontrol scontrol can delegate commands to specific job ids and nodes please note that many scontrol commands can only be executed as user root you can use these commands with a job id to adjust scontrols output suspend to pause a jobs processes resume to continue a jobs processes hold to make a job a lower priority putting it on hold so higher priority jobs will run first release to remove a job from the hold list show job to get detailed information about a job',\n",
       " 'sidebar_position 4 logging in to the controller clusters use one node called a controller to delegate tasks to compute nodes so they can carry out commands and complete jobs you can complete many tasks on the pw platform after logging in to the controller such as submitting jobs and transferring data there are multiple ways to log in to the controller from within the platform logging in with a resource name after youve started a cluster copy its name from the computing resources box expand the ide by clicking the icon if a terminal doesnt appear in the ide automatically you can open one by selecting terminal  new terminal by default the terminal will show usernamepwuserusernamepw enter the command ssh resourcenameclusterspw the terminal will display the message warning permanently added resourcenameclusterspw ecdsa to the list of known hosts as well as your last login and location logging in with an ip address after youve started a cluster click on its ip address in the computing resources box to copy it expand the ide by clicking the icon if a terminal doesnt appear in the ide automatically you can open one by selecting terminal  new terminal by default the terminal will show usernamepwuserusernamepw enter the command ssh usernameipaddress the terminal will display your last login and location info note each time you start a cluster the controller will be assigned a random ip address from the cloud providers available addresses if you stop the cluster this ip address is released automatically and will most likely not be the same when you start the cluster again although its unlikely that youll encounter the same cluster ip address it may occur if you start and stop a cluster frequently you may receive the following message warning remote host identification has changed to resolve the issue enter the command sshkeygen r controlleripaddress you should see the following message shell demopwuserdemo   sshkeygen r 35224100236 host 35224100236 found line 137 usersdemosshknown_hosts updated original contents retained as usersdemosshknown_hostsold demopwuserdemo   ssh canaryparallelworks the authenticity of host 35224100236 cant be established ed25519 key fingerprint is sha256kzr9scw5qkmiceh2e5z7zhpgadououubnpkqj8uqsog this key is not known by any other names are you sure you want to continue connecting yesnofingerprint  enter yes youll see a message that the ip address has been added to the list of known hosts shell warning permanently added 35224100236 ed25519 to the list of known hosts last login wed jan 11 164036 2023 from 1046019063lightspeedhstntxsbcglobalnet demopwuserdemo   from outside the platform logging in with configuration settings if you want to access a cluster from the terminal or command line on your computer you can use an ssh key to log in to the controller see what if i dont have an ssh key below if you need help while your cluster is off navigate to your clusters configuration settings by clicking its gear icon in the computing resources box or by clicking its name in the resources tab paste your public ssh key into the access public key dialog box and select save resource now you can start the cluster once the cluster is active navigate to the terminal or command line on your device and enter the clusters ip address with ssh usernameipaddress youll receive the message are you sure you want to continue connecting yesnofingerprint enter yes the terminal or command line will display warning permanently added resourcenameclusterspw ecdsa to the list of known hosts as well as your last login and location now you can send commands to the controller from your remote device logging in with account settings you can also add an ssh key to your pw account which will allow you to log in to any active cluster from any device with that ssh key on it navigate to your account page username  account in the authentication tab click  add ssh key in the key field paste your public ssh key enter a name for your key in the title field click add key you can now log in to any active cluster navigate to the terminal or command line on your device and enter ssh i pathtosshprivatekey usernameipaddress shell parallelworksparallelsmacbookair sshtest  ssh i id_rsa demo3413524147 last failed login thu mar 2 094820 utc 2023 from 6094197104bcgoogleusercontentcom on sshnotty demodemocluster70   faq why dont i have to use an ssh key from within the platform each users workspace has an ssh key preprovisioned so logging in to the controller through the ide doesnt require ssh key management the public key is automatically propagated to the controller while the private key stays inside your workspace whenever you start a new cluster a new key is generated and propagated to facilitate ssh to compute nodes this process works because the home directory is shared across all nodes in the cluster adding your public workspace key to the authorized_keys file on the controller automatically allows you to ssh to the compute nodes too you can access your public workspace key at any time with the command cat sshpw_id_rsapub in an ide terminal why do i see __ failed login attempts the first time i log in to the controller these failed login attempts wont affect your clusters performance theyre a result of how our platform communicates with cloud service providers to make resources available during the provisioning process our platform repeatedly tries to ssh to the controller while the controller comes online the platform attempts to establish a tunnel connection from the user workspace to the controller because the user workspace key isnt available on the system until partway through the bootstrap process the system registers some of these connection attempts as failures below is a diagram of this process what if i dont have an ssh key the steps below will guide you through finding and creating ssh keys on your device for both macos and windows info note the instructions in this section will work on windows if you use a shell emulator like git bash or powershell if you use putty to manage your ssh keys on windows see what if i use putty below  check for ssh keys open terminal macos or command prompt windows enter ls ssh to check for ssh keys on your device if youve never generated an ssh key youll see the message ls ssh no such file or directory if you do have ssh keys on your device theyll be listed if you want to use one of your existing keys see get your public key below create an ssh key enter sshkeygen youll see the following message shell generating publicprivate rsa key pair enter file in which to save the key usersyourname sshid_rsa type the name of the new location or press returnenter if you want to keep the default location if this is the first time youve generated an ssh key and you use the default location youll see created directory  usersyourname ssh youll be prompted to enter a passphrase for your ssh key with the following message shell enter passphrase empty for no passphrase enter same passphrase again enter a passphrase or press returnenter for both lines if you dont want to use one youll see the following message along with your key fingerprint and the keys randomart image shell your identification has been saved in usersyourname sshid_rsa your public key has been saved in usersyourname sshid_rsapub enter ls ssh again now youll see your private and public ssh keys get your public key enter cat sshid_rsapub youll see the full contents of your public ssh key copy all of the text from the beginning of sshrsa to the end of local this is what youll paste into the access public key box in your clusters configuration settings or the key box in account  authentication  key caution important for safetys sake never store a private ssh key on a server if someone gained access to your private key they could use it to access any other device that key protects  what if i use putty public ssh keys must be in openssh format before you can use them on the pw platform if you use putty your ssh keys are likely saved in a ppk format like this shell puttyuserkeyfile2 sshrsa encryption none comment rsakey20211005 publiclines 6 aaaab3nzac1yc2eaaaabjqaaaqeao7fygiresvecemn3clxkgqhg5kcqtel4vu x81zolf1p8rjsjcnlrrd0o2zfquhanfbykadso6vpg18eyhiqahgeogzuaf7 tq4oazl3yvyjkjzxqdxhnrhnjmcj438pjd69crqh4apgtupqujookje1pcpcp7fy p2y2hb0wm23k60twsml9wf2p6gsyvyxvwnlohja9luy2dtk39kcs5tmiofhi toe3zjxzytv0xllnfgjxm1gv38yia9r9fzdmxqm2hihfbt5ybb6mabbrdhvto dlha0y8oitqosmoga13mocfyllbgou65ehtnj9talkex3lgdw before copying a ppk key it must be converted to openssh format the easiest way to do this is with puttygen typically included with putty installations below is a cli example using puttygen to convert a ppk key to openssh format shell  puttygen putty_keyppk l o putty_keypub command explanation putty_keyppk  the source key file l  openssh public key output type o putty_keypub  the output file name  the result is a single line public key file in openssh format shell  cat putty_keypub sshrsa aaaab3nzac1yc2eaaaabjqaaaqeao7fygiresvecemn3clxkgqhg5kcqtel4vux81zolf1p8rjsjcnlrrd0o2zfquhanfbykadso6vpg18eyhiqahgeogzuaf7tq4oazl3yvyjkjzxqdxhnrhnjmcj438pjd69crqh4apgtupqujookje1pcpcp7fyp2y2hb0wm23k60twsml9wf2p6gsyvyxvwnlohja9luy2dtk39kcs5tmiofhitoe3zjxzytv0xllnfgjxm1gv38yia9r9fzdmxqm2hihfbt5ybb6mabbrdhvtodlha0y8oitqosmoga13mocfyllbgou65ehtnj9talkex3lgdw rsakey20211005 now you can copy and paste this key into the clusters configuration settings on the pw platform',\n",
       " 'sidebar_position 2 running workflows info about jobs there are two ways you can submit jobs to a cluster by using workflows or through any terminal or commandline interface for the commandline interface option please see submitting jobs via slurm  after youve started a cluster navigate to the workflows tab and select the workflow youd like to use if you havent added any workflows you can select one from the marketplace select username  marketplace when you click the name of your workflow a settings box will open in the run workflow tab enter any necessary parameters then click the cloud icon  a new window for resource configuration will open enter any necessary variables then use the default resource dropdown to select a cluster thats already running click the x in the upperright corner to save the settings click execute youll see a green box with the message 1 job has been successfully added to the queue now you can navigate to the compute tab to check your jobs progress the workflow monitor box displays jobs in descending order starting with the most recently submitted once a job is completed you can go to the jobs folder in the ide pane to check your jobs output with the stdout file info note the example workflow used here is testlaunch which has only two parameters meant for testing purposes many workflows on the pw platform have additional parameters especially those that execute multiple or more complex tasks if you need help with setting parameters you can reach out to your admin or to us at any time ',\n",
       " 'sidebar_position 8 sidebar_label creating an organization bootstrap script title  about organization bootstrap scripts this page explains how to add a bootstrap script for your organization the script will run whenever a user in your organization starts a cluster in their account this feature is useful for automating tasks such as sending platform data to a specific location info persona the steps included on this page should be completed by a pw platform administrator in your organization  navigating to organization bootstrap settings navigate to your organization settings username  organization in organization settings click providers in providers scroll down to the bootstrap section enter your bootstrap script in the text box this text will run as a bash script during cluster provisioning when youre done click save your changes will be applied immediately info note if a user adds their own bootstrap script in a clusters configuration settings the script you set with the instructions will run before the users added script  testing a sample bootstrap script you can test this feature with a simple script that echoes text in a designated file enter the following command in the bootstrap script box bash echo hello world  tmporgbootout exit 0  click save navigate to the compute tab start one of your clusters when the cluster is active log in to the controller with ssh for detailed instructions on that process please see logging in to the controller after logging in navigate to tmp read orgbootout to see that it matches the echo command info note if you encounter errors during this test please contact us ',\n",
       " 'sidebar_position 1 creating users this page explains how to add new users to the pw platform info persona the steps included on this page can only be completed by pw platform administrators and users with either the orgadmin or orgusers role for more information please see about group roles  creating new users individually this method is useful if you only need to add one or two new users to your organization navigate to your organization settings username  organization on the next page click users in users click  add user on the next page enter these credentials for the new user name username email password location optional when youre finished click create account the new user will now be listed in the users tab mass importing new users this method is useful if you need to add several new users at once navigate to your organization settings username  organization in organization settings click users in users click import users on the next page click download template your browser will download a csv file which you can open in any spreadsheet editor like excel or numbers in the template enter these credentials for the new users username password optional name email address uid optional groups optional active status on the platform click upload template and select your edited file check that the preview for the new users is correct click import users an import log will appear at the bottom of the screen if any errors occurred during the importing process they will be displayed here the new users will now be listed in the users tab info troubleshooting on macos sometimes your system will save a csv file as a numbers file likewise excel will prompt you to save a csv file as an excel format instead such as xls however please note that the user import feature only accepts csv files ',\n",
       " 'sidebar_position 5 configuring providers about providers providers affect which resources your users can create or start limiting providers is useful if users in your organization only need certain types of resources please note that providers are an aggregated feature which means that the visible providers for users are a combination of your organizationlevel settings and grouplevel settings example if your organization enables only google clusters but a group enables only azure clusters that groups users will be able to create both google and azure clusters if instead your organization has all providers disabled but a group has azure clusters enabled that groups users will be able to create azure clusters lastly if your organization has only google clusters enabled but a group has all providers disabled that groups users will be able to create google clusters enabling providers this section explains how to choose which providers your pw organization will be able to access info persona the steps included on this page can only be completed by pw platform administrators and users with the orgadmin role for more information please see about group roles  navigate to your organization settings username  organization on the next page click providers all of our currently offered resource types are listed in providers if default settings is selected users will have access to all resources from all providers the checkboxes for providers are locked while default settings is selected select custom settings to make changes to enable providers click the empty checkbox for whichever resources you want your organization to have to remove providers click the blue checkboxes to disable existing resources by default all items under resource name are collapsed but will expand when you click them you can then select or deselect individual resource types under each category when youre done click save provider settings your changes will be applied immediately info customizing default providers if you follow these steps your changes will apply only to the organization youre in the organization name you see when you first navigate to the organization page ',\n",
       " 'sidebar_position 6 configuring instance types this page explains how to choose which instance types users will have access to when they configure clusters in the resources tab this feature is useful if for example your users only need a certain amount of power for their work in that case you can limit instances to only lower cpu types info persona the steps included on this page can only be completed by pw platform administrators and users with the orgadmin role for more information please see about group roles  navigate to your organization settings username  organization on the next page click providers in providers navigate to allowed instance types if default settings is selected users will have access to all instance types select custom settings to make changes you can customize instance types on aws azure and google resources use the arrows for each csp to open their dropdown menus click the instance types you want to add the instance types you select will appear in the list below the dropdown menus when youre done click save instance types your changes will be applied immediately',\n",
       " 'sidebar_position 3 sidebar_label managing groups title  import  fatrash  from reacticonsfa about groups this page explains the major features of pw groups we use groups on the platform to assign user permissions designate cost allocations manage cloud service providers and share resources between users info persona the steps included on this page can only be completed by users with either the orgadmin or orggroups role for more information please see about group roles  navigating to the groups page navigate to your organization settings username  organization on the next page click groups creating groups in the groups tab click  new group enter a name for your group optionally enter a description click create group the new group will now be listed in the groups tab adding users to groups after you create a group you can add new members to it on the same page under manage users in group use the dropdown menu to select a member in your organization click add member the new user will now be listed with the other group members below the dropdown menu info about groups because group is a cluster configuration setting we recommend letting your users know if theyre in multiple groups and which group they should use for their clusters  removing users from groups if you need to remove members from a group click the remove icon next to the users name after you click the remove icon a dialog box will appear with the message removing user username from group click cancel to go back or remove user to remove the user from the group if you click remove user the user will no longer appear in the list of group members below the dropdown menu info about removing users removing a user from a group will only affect their permissions and which group they may use to provision cloud resources their account and their access to the platform will not be affected  assigning roles to add roles click the empty checkbox for whichever permissions you want this group to have to remove roles click the blue checkboxes to disable existing permissions when youre done click save roles your changes will be applied immediately editing allocations info persona the steps included in this section can only be completed by pw platform administrators and users with the orgadmin role  in the groups tab click edit cost allocations enter a value in the allocation total field this number is measured in us dollars when a group reaches its allocation total its users will no longer be able to start clusters click save allocations once youve set an allocation total a groups accumulated cost will appear in the allocation used column users will see a warning on their clusters if their groups accumulated cost is approaching its allocation total',\n",
       " 'sidebar_position 9 restarting user workspaces this page explains how to restart user workspaces this feature is useful if a user is experiencing errors on the platform info persona the steps included on this page can only be completed by pw platform administrators and users with the orgadmin role for more information please see about group roles  navigate to your organization settings username  organization on the next page click users in users click the users name in the users profile settings click restart workspace a dialog box will appear with the message are you sure you want to restart users workspace click restart after the workspace has restarted youll see the message user workspace killed info troubleshooting please contact us if you restarted the workspace because the user was experiencing errors and the errors arent resolved after restarting ',\n",
       " 'sidebar_position 7 title  sidebar_label configuring default resources about default resources this page explains how to choose which resources new users will be able to access when they navigate to the resources tab this feature is useful if youve configured a cluster in your account and want your organizations users to have those configuration settings available when you choose a default resource for new users a copy of that resource is made whenever you create new accounts these default resources are separate other users will not be affected if work is completed on a default resource or changes are made to its configuration settings configuring default resources info persona the steps included on this page can only be completed by pw platform administrators and users with either the orgadmin or orgsettings role for more information please see about group roles  navigate to your organization settings username  organization in settings click the dropdown menu under new users  default resources to see resources from your account in the dropdown menu click the resource you want to add for new users the resource will appear in the list below the dropdown menu when youre done adding resources click save default resource your changes will be applied immediately',\n",
       " 'sidebar_position 1 preparing aws this page explains how to set up an aws account so its ready for the pw platform to manage infrastructure clusters billing storage and usage data info persona the steps included on this page should be completed by a cloud engineer in your organization  aws account we recommend creating a new aws account for the pw platform which will allow you to keep your existing aws account separate from the platform and make it easier to manage billing and usage data this will also ensure the principle of least privilege as the pw platform will only have access to the resources it needs to manage if you use aws organizations you can create a new account within your organization otherwise you can make a nonorganization account setting up aws credentials to get started quickly you can create a new iam user and assign the administratoraccess awsmanaged policy to it alternatively you can create the policies listed in aws policies below then attach those policies to the iam user create an access key the pw platform requires the use of an aws access key to authenticate with aws if you dont have an access key you can create one info security best practices the pw platform will immediately rotate the secret access key after its entered into the system the platform will then use the rotated secret access key to generate shortterm credentials which will be used by all pw platform services for more information about aws keys and security best practices see this faq on the aws website  aws policies this section includes the policies youll need to attach to the iam user you create for the pw platform you can create these policies in the iam console or you can create them in the aws cli by entering the json files listed under each policy pwinfraclusters this policy is used for creating clusters json  version 20121017 statement   effect allow action  ec2authorizesecuritygroupingress ec2describeinstances ec2createkeypair ec2createimage ec2copyimage ec2describesnapshots ec2describeplacementgroups ec2deletevolume ec2modifysnapshotattribute ec2createplacementgroup ec2describevolumes ec2describekeypairs ec2detachvolume fsxlisttagsforresource ec2importkeypair ec2createtags ec2registerimage ec2modifynetworkinterfaceattribute route53changeresourcerecordsets ec2deletenetworkinterface fsxuntagresource ec2runinstances ec2stopinstances ec2createvolume ec2createnetworkinterface ec2getpassworddata ec2describeimageattribute ec2describeinstancetypes ec2associateaddress ec2describesubnets ec2deletekeypair ec2attachvolume ec2disassociateaddress fsxdescribefilesystems ec2deregisterimage ec2deletesnapshot ec2describeinstanceattribute ec2describeregions ec2modifyimageattribute iampassrole ec2describenetworkinterfaces ec2createsecuritygroup ec2createsnapshot ec2modifyinstanceattribute fsxtagresource ec2describeinstancestatus ec2terminateinstances ec2detachnetworkinterface ec2deleteplacementgroup ec2describetags ec2describesecuritygroups fsxdeletefilesystem ec2describeimages ec2describevpcs ec2deletesecuritygroup fsxcreatefilesystem ec2attachnetworkinterface  resource     pwinfracreate this policy is used to create base infrastructure json  version 20121017 statement   effect allow action  ec2associatedhcpoptions ec2associateroutetable ec2attachinternetgateway ec2authorizesecuritygroupegress ec2authorizesecuritygroupingress ec2createdhcpoptions ec2createinternetgateway ec2createnatgateway ec2createroute ec2createroutetable ec2createsecuritygroup ec2createsubnet ec2createvpc ec2describeaccountattributes ec2describeaddresses ec2describeavailabilityzones ec2describedhcpoptions ec2describeinternetgateways ec2describenatgateways ec2describenetworkacls ec2describeroutetables ec2describesecuritygroups ec2describesubnets ec2describevpcattribute ec2describevpcclassiclink ec2describevpcclassiclinkdnssupport ec2describevpcs ec2modifyvpcattribute ec2revokesecuritygroupegress ec2createtags ec2allocateaddress iamaddroletoinstanceprofile iamcreateaccesskey iamcreateinstanceprofile iamcreaterole iamcreateuser iamgetinstanceprofile iamgetrole iamgetrolepolicy iamgetuser iamlistattachedrolepolicies iamlistrolepolicies iamputrolepolicy iamputuserpolicy iamtagrole iamtaguser iampassrole route53changetagsforresource route53createhostedzone route53getchange route53gethostedzone route53listresourcerecordsets route53listtagsforresource stsgetcalleridentity  resource     pwinfradelete this policy is used to delete base infrastructure json  version 20121017 statement   effect allow action  stsgetcalleridentity stsgetcalleridentity ec2describeaccountattributes ec2describeavailabilityzones ec2describeaddresses ec2describevpcs ec2deletetags iamgetuser iamgetrole iamuntagrole iamuntaguser ec2describevpcattribute iamlistrolepolicies iamlistaccesskeys iamgetuserpolicy ec2describevpcattribute iamgetrolepolicy iamlistattachedrolepolicies ec2describevpcclassiclink iamgetinstanceprofile iamgetrolepolicy ec2describevpcclassiclinkdnssupport iamgetrole ec2describeroutetables ec2describenetworkacls ec2describesecuritygroups ec2describeroutetables ec2describesubnets ec2describesubnets ec2describesubnets ec2describesubnets ec2describesubnets ec2describesubnets ec2describesubnets ec2describesubnets ec2describesubnets ec2describesecuritygroups ec2describesubnets ec2describeinternetgateways route53gethostedzone ec2describesubnets ec2describesubnets ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2describenatgateways ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2describeroutetables route53listresourcerecordsets ec2describeroutetables route53listtagsforresource ec2describedhcpoptions ec2describevpcs stsgetcalleridentity stsgetcalleridentity ec2describeaccountattributes ec2disassociateroutetable ec2disassociateroutetable iamdeleteaccesskey iamdeleteuserpolicy iamremoverolefrominstanceprofile ec2disassociateroutetable ec2disassociateroutetable ec2disassociateroutetable ec2associatedhcpoptions ec2deleteroute iamdeleteinstanceprofile iamdeleterolepolicy ec2disassociateroutetable ec2disassociateroutetable ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2disassociateroutetable ec2describeroutetables ec2describenetworkinterfaces ec2describeroutetables ec2describeroutetables ec2describeroutetables ec2disassociateroutetable ec2disassociateroutetable ec2disassociateroutetable ec2disassociateroutetable ec2deleteroute ec2describeroutetables ec2describeroutetables ec2describeroutetables iamlistgroupsforuser ec2deletedhcpoptions ec2describeroutetables ec2describeroutetables iamdeleteuser ec2describeroutetables ec2describenetworkinterfaces iamlistinstanceprofilesforrole ec2describeroutetables ec2describeroutetables iamlistrolepolicies ec2describenetworkinterfaces ec2describenetworkinterfaces ec2describenetworkinterfaces ec2describenetworkinterfaces ec2describenetworkinterfaces route53listresourcerecordsets iamdeleterole ec2deletesubnet ec2deletesubnet ec2deletesubnet ec2deletesubnet ec2deletesecuritygroup ec2deletesubnet ec2describeroutetables ec2deletenatgateway ec2describeroutetables ec2deletesubnet ec2deleteroutetable ec2describeroutetables route53getdnssec route53deletehostedzone ec2describenatgateways ec2describenatgateways ec2describenatgateways ec2describenatgateways ec2describenatgateways ec2describenetworkinterfaces ec2describenetworkinterfaces ec2describenetworkinterfaces ec2describenetworkinterfaces ec2describeaddresses ec2describenetworkinterfaces ec2describenetworkinterfaces ec2deletesubnet ec2deletesubnet ec2deletesubnet ec2deletesubnet ec2deletesubnet ec2deletesubnet ec2releaseaddress ec2detachinternetgateway ec2deleteinternetgateway ec2deletevpc  resource     pwbilling this policy is used to access billing information json  version 20121017 statement   effect allow action  s3getlifecycleconfiguration s3getbuckettagging s3putaccelerateconfiguration s3deleteobjectversion s3listbucketversions s3getbucketlogging s3createbucket s3listbucket s3getaccelerateconfiguration s3getbucketpolicy s3putencryptionconfiguration s3getobjectacl s3getencryptionconfiguration s3getbucketobjectlockconfiguration s3putbuckettagging s3getbucketrequestpayment s3putlifecycleconfiguration s3putbucketacl cur s3deleteobject s3deletebucket s3putbucketversioning s3putobjectacl s3getbucketpolicystatus s3getbucketwebsite s3putreplicationconfiguration s3getbucketversioning s3putbucketcors s3getbucketacl s3deletebucketpolicy s3getreplicationconfiguration s3putobject s3getobject s3putbucketwebsite s3listallmybuckets s3putbucketrequestpayment s3putbucketlogging s3getbucketcors s3putbucketpolicy s3putbucketobjectlockconfiguration s3getbucketlocation s3getobjectversion  resource    ',\n",
       " 'sidebar_position 3 preparing google this page explains how to set up a google account so its ready for the pw platform to manage infrastructure clusters billing storage and usage data info persona the steps included on this page should be completed by a cloud engineer in your organization  google account we recommend creating a new google project for the pw platform which will allow you to keep your existing google project separate from the platform and make it easier to manage billing and usage data this will also ensure the principle of least privilege as the pw platform will only have access to the resources it needs to manage setting up google credentials to get started quickly you can create a new service account and add the owner role this will allow the pw platform to manage all resources in your project if you want to limit the scope of the service account you can create a custom role and assign it to the service account creating a service account key the pw platform uses service account keys to authenticate with google cloud you can create a new service account key by following the steps on the google documentation google permissions this section includes the permissions or roles youll need to assign to the google service account you create for the pw platform you can create a custom role with all the needed permissions in the iam console pwbilling these permissions are used to provision and access billing infrastructure you can also assign the existing google iam roles bigquery user and service usage admin to your google service account json serviceusageoperationsget serviceusageservicesdisable serviceusageservicesenable serviceusageservicesget serviceusageserviceslist monitoringtimeserieslist serviceusageoperationscancel serviceusageoperationsdelete serviceusageoperationslist serviceusagequotasget serviceusagequotasupdate serviceusageservicesuse bigquerydatasetscreate bigquerydatasetsget bigqueryjobscreate bigquerytableslist resourcemanagerprojectsget bigquerybireservationsget bigquerycapacitycommitmentsget bigquerycapacitycommitmentslist bigqueryconfigget bigquerydatasetsgetiampolicy bigqueryjobslist bigquerymodelslist bigqueryreadsessionscreate bigqueryreadsessionsgetdata bigqueryreadsessionsupdate bigqueryreservationassignmentslist bigqueryreservationassignmentssearch bigqueryreservationsget bigqueryreservationslist bigqueryroutineslist bigquerysavedqueriesget bigquerysavedquerieslist bigquerytransfersget bigquerymigrationtranslationtranslate resourcemanagerprojectslist',\n",
       " 'sidebar_position 2 preparing azure this page explains how to set up an azure subscription so its ready for the pw platform to manage infrastructure clusters billing storage and usage data info persona the steps included on this page should be completed by a cloud engineer in your organization  azure subscription we recommend creating a new azure subscription for the pw platform which will allow you to keep your existing azure subscription separate from the platform and make it easier to manage billing and usage data this will also ensure the principle of least privilege as the pw platform will only have access to the resources it needs to manage to learn more about azure subscriptions please see the azure documentation setting up azure credentials to get sarted quickly you can create a new service principal and add the contributor role this will allow the pw platform to manage all resources in your subscription if you want to limit the scope of the service principal you can create a custom role and assign it to the service principal creating a client secret the pw platform uses azure client secrets to authenticate with azure you can create a new client secret by following the steps in the azure documentation azure access policies pwbilling assign the following predefined roles to your application in order for the pw platform to provision billing infrastructure and access true cost data json contributor storage blob data contributor',\n",
       " 'sidebar_position 4 import tabs from themetabs import tabitem from themetabitem adding a cloud account this page explains how to add cloud service provider keys to your pw organization which will allow you to provision infrastructure that all members of your organization can use to start clusters info persona the steps included on this page should be completed by an administrator in your organization  navigate to your organization settings username  organization on the next page click keys in keys click  new key select your cloud service provider from the type dropdown menu next youll add your cloud account key this process looks slightly different for each cloud service provider you can choose the one youre using from the options below aws uses access keys for authentication youll need both your access key and private access key to add your aws account to the pw platform if you dont have an access key you can create one azure uses service principles authenticated through a client secret youll need your client id tenant id client secret and subscription id to add your azure account to the pw platform if you dont have a principal secret you can create one google uses service account keys for authentication youll need the json file of the key to add your google account to the pw platform if you dont have a service account key you can create one after entering your credentials click create cloud key on the next page youll see the message security credentials added your new key will be listed in the keys tab',\n",
       " 'about billing infrastructure csps provide resource usage and cost reports to customers at set intervals parallel works refers to this as the true cost data each csps cost export feature ultilizes unique cloud infrastructure and has a unique data format the pw platform can provision the necessary infrastructure to enable csp billing exports on each cloud please see configuring billing infrastructure for more details alternatively organizations may manually enable csp billing data exports by following steps for each csp they will use with the platform for aws please see the aws guide on creating cost and usage reports for azure please see the azure guide on creating and managing exported billing data for google please see the google guide on setting up cloud billing data exports once data exports are configured the pw platform pulls formats and stores true cost data from each csp platform users and organization administrators can see true cost data on the cost dashboard documention link coming soon which is a convenient onestop page for users to track their usage across all csps without having to refer to each csps cost management console below you can find specific details about the implementation of the billing infrastructure for each csp aws billing infrastructure deploying billing infrastructure provisions the following on aws cost usage report exports aws cost data periodically s3 bucket stores exported aws cost data the schematic below shows how the pw platform communicates with aws cloud after the billing infrastructure is created azure billing infrastructure deploying billing infrastructure provisions the following on azure cost export exports azure cost data daily billing resource group groups the storage account and container storage account an account to contain the blob storage container blob container stores exported azure cost data cost management export provider registers the necessary provider for cost export not included in the diagram the schematic below shows how the pw platform communicates with azure cloud after the billing infrastructure is created google billing infrastructure deploying billing infrastructure provisions the following on google bigquery dataset stores exported google cost data bigquery data transfer api enables the necessary api to export data to bigquery not included in the diagram the schematic below shows how the pw platform communicates with google cloud after the billing infrastructure is created',\n",
       " 'sidebar_position 1 creating billing infrastructure this page explains how to provision billing infrastructure in your pw account which will allow pw to access process and display billing data in the cost dashboard info persona the steps included on this page should be completed by an administrator in your organization  navigate to your organization settings username  organization on the next page click infrastructure in infrastructure click  new infrastructure select a saved key from the key dropdown menu if you dont have any saved keys you can add one enter a name for the infrastructure please note that this text must be lowercase alphanumeric select billing infrastructure click  create infrastructure next youll configure the infrastructure this process looks slightly different for each cloud service provider please see configuring billing infrastructure for more information  after configuring your infrastructure click save billing youll see the automated message infrastructure updated click deploy infrastructure the provisioning log will display the progress of the provisioning and deployment process which takes up to five minutes if you click the infrastructure tab your new infrastructure configuration will be listed there info note currently you can only configure one billing infrastructure per organization regardless of which csp or region youre using ',\n",
       " 'sidebar_position 2 configuring billing infrastructure this page explains how to configure billing infrastructure according to cspspecific parameters info persona the steps included on this page should be completed by an administrator in your organization  functionalities to change the infrastructures configuration click the definition tab the buttons in this tab have the following functions save billing saves the current configuration parameters whenever you change any field in the infrastructure configuration form use this button to ensure your changes arent lost delete configuration deletes the current billing infrastructure configuration if you use this button the infrastructure configuration will not appear in your list of configured infrastructures deploy infrastructure provisions the billing infrastructure destroy infrastructure deprovisions the billing infrastructure force unlock releases the billing infrastructure from a locked state so the infrastructure can be redeployed this button is useful if the infrastructure provisioner fails during the deployment process for more information see troubleshooting below to see the code version of the configuration settings click the _ json tab to change the infrastructures name click the properties tab info about importing there is also an imported option that works for all csps use this option if you have already provisioned or configured billing infrastructure in your csp account and want the pw platform to access and process your billing data the pw platform does not manage imported billing infrastructure our system assumes this infrastructure has already been provisioned and is ready for use imported billing infrastructure cannot be provisioned or destroyed  info about deletion if you want to delete a configuration from the list in infrastructure you first need to deprovision the infrastructure on its configuration page if you dont the infrastructure will still exist in your csp account  aws billing infrastructure pw provisioned aws billing infrastructure select the region that you want your billing infrastructure to be deployed in for more information about regions see the aws documentation imported aws billing infrastructure toggle the imported button to yes enter your s3 bucket name and select the region that the bucket was provisioned in info note the pw platform manages billing data by attaching tags to the provisioned cloud resources to enable the necessary tags in your aws billing data youll need to activate custom tags in your aws account please see the aws documentation for the required permissions to complete the steps listed below  log in to the aws management console navigate to the billing page click on cost allocation tags in the tab for userdefined allocation tags activate these tags date groupid name organizationid pool project session sessionid user azure billing infrastructure pw provisioned azure billing infrastructure select the region that you want your billing infrastructure to be deployed in for more information about regions see the azure documentation toggle the cost management export button to yes if you have not yet registered the microsoftcostmanagementexports provider in your azure subscription if you toggle the button to yes but have already registered the microsoftcostmanagementexports provider the provisioner will fail because azure will deny the new registration attempt for more details about providers please see the azure documentation imported azure billing infrastructure toggle the imported button to yes enter the storage account name and the blob container name that youve configured to store your azure billing data google billing infrastructure pw provisioned google billing infrastructure select the region that you want your billing infrastructure to be deployed in for more information about regions see the google documentation in the project field enter the project id of the project that you want this billing infrastructure to be deployed in your google credential key will need to have certain permissions enabled in this project id for more information about these required permissions see preparing google info note at the time of writing this page google does not have an automated option to export billing data to the provisioned bigquery dataset so this task must be performed manually you will need the role billing exporter in your billing account to complete the steps listed below  log in to google cloud console navigate to the billing page click on billing export and select detailed usage cost for project choose the project that you provisioned the bigquery dataset in for dataset choose the bigquery dataset that has just been provisioned the dataset name will have the format of yourogranizationbilling click save for more information please see step 5 of the google guide on setting up cloud billing imported google billing infrastructure toggle the imported button to yes enter the bigquery dataset name and the project id that the dataset was provisioned in troubleshooting after clicking deploy infrastructure you wont be able to edit the configuration settings while the infrastructure is being built all fields and buttons will be grayed out except for destroy infrastructure and force unlock if the provisioning log displays any errors in red you can retry the provisioning process by clicking destroy infrastructure which will delete all of the provisioned elements then you can click deploy infrastructure to retry the provisioning process if the errors persist you can click force unlock doing so will allow you to edit the configuration settings or delete the infrastructure with delete configuration caution warning please monitor the provisioning log and wait for the provisioning process to finish before attempting to force unlock and retry deploy infrastructure or destroy infrastructure do not force unlock and deploy infrastructure while the provisioning process is still running doing so will fail and cause unwanted issues  if the errors persist after trying to redeploy or reconfigure the infrastructure please contact us',\n",
       " 'about deployment  base infrastructure in order to provision cloud clusters you must first deploy a base set of infrastructure into your csp account throughout our documentation we refer to this as the base infrastructure this base infrastructure is shared by multiple clusters and varies for each csp in essence you can think of it as the networking stack which clusters will be deployed on top of below you can find specific details about the implementation of this base infrastructure for each csp aws infrastructure deploying base infrastructure provisions the following on aws a virtual private cloud vpc an internet gateway public and private subnets public and private route tables and routes a network address translation nat gateway an elastic ip address for the nat gateway a route 53 hosted zone a security group the schematic below shows a pwdeployed cluster in aws cloud the controller and compute nodes are shown in availability zone useast1a inside the useast1 region all compute nodes in a region use a single nat gateway for outbound internet connectivity this nat gateway is preprovisioned as part of the base infrastructure the ami used for the controller and compute nodes is inside the parallel works aws account info expense information creating a nat gateway will result in an additional monthly charge in your aws account for more information please see this aws pricing list ',\n",
       " 'sidebar_position 2 configuring base infrastructure this page explains how to configure base infrastructure according to cspspecific parameters info persona the steps included on this page should be completed by an administrator in your organization  functionalities to change the infrastructures configuration click the definition tab the buttons in this tab have the following functions save base saves the current configuration parameters whenever you change any field in the infrastructure configuration form use this button to ensure your changes arent lost delete configuration deletes the current base infrastructure configuration if you use this button the infrastructure configuration will not appear in your list of configured infrastructures deploy infrastructure provisions the base infrastructure destroy infrastructure deprovisions the base infrastructure force unlock releases the base infrastructure from a locked state so the infrastructure can be redeployed this button is useful if the infrastructure provisioner fails during the deployment process for more information see troubleshooting below to see the code version of the configuration settings click the _ json tab to change the infrastructures name click the properties tab info about deletion if you want to delete a configuration from the list in infrastructure you first need to deprovision the infrastructure on its configuration page if you dont the infrastructure will still exist in your csp account  aws infrastructure select the region that you want your infrastructure to be deployed in for more information about regions see the aws documentation azure infrastructure select the region that you want your infrastructure to be deployed in for more information about regions see the azure documentation in vm image resource group id enter the resource id of the resource group you want this infrastructure to be associated with if you dont have a resource group you can create one you can find the resource id in the azure portal by navigating to home  payasyougo  resource groups  groupname  properties  resource id in vm image resource group name enter the name of the resource group you want this infrastructure to be associated with in nat ip availability zone enter the availability zone that you want your infrastructures ip address to be deployed in we suggest entering zoneredundant in this field for more information about availability zones see the azure documentation google infrastructure enter the project id of the project that you want this infrastructure to be deployed in if you dont have a project please see preparing google select the region and availability zone that you want your infrastructure to be deployed in for more information about regions and availability zones see the google documentation troubleshooting after clicking deploy infrastructure you wont be able to edit the configuration settings while the infrastructure is being built all fields and buttons will be grayed out except for destroy infrastructure and force unlock if the provisioning log displays any errors in red you can retry the provisioning process by clicking destroy infrastructure which will delete all of the provisioned elements then you can click deploy infrastructure to retry the provisioning process if the errors persist you can click force unlock doing so will allow you to edit the configuration settings or delete the infrastructure with delete configuration caution warning please monitor the provisioning log and wait for the provisioning process to finish before attempting to force unlock and retry deploy infrastructure or destroy infrastructure do not force unlock and deploy infrastructure while the provisioning process is still running doing so will fail and cause unwanted issues  if the errors persist after trying to redeploy or reconfigure the infrastructure please contact us',\n",
       " 'sidebar_position 1 creating base infrastructure this page explains how to provision base infrastructure in your pw account which will allow all members of your organization to work with clusters info persona the steps included on this page should be completed by an administrator in your organization  navigate to your organization settings username  organization on the next page click infrastructure in infrastructure click  new infrastructure select a saved key from the key dropdown menu if you dont have any saved keys you can add one enter a name for the infrastructure please note that this text must be all lowercase select base infrastructure click  create infrastructure next youll configure the infrastructure this process looks slightly different for each cloud service provider please see configuring base infrastructure for more information  after configuring your infrastructure click update infrastructure configuration youll see the automated message infrastructure updated click deploy infrastructure the provisioning log will display the progress of the provisioning and deployment process which takes up to five minutes if you click the infrastructure tab your new infrastructure configuration will be listed there info about regions currently you can only configure one infrastructure per region regardless of which csp youre using if youd like to add a second infrastructure with the same csp in a different region youll need to deploy another infrastructure ']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_doc_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Pre-processing the Documentation Data\n",
    "\n",
    "In this section, we'll take our cleaned documentation data from Step 2 and pre-process it by tokenization, stemming lemmatization, and stop-word removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_doc_data(cleaned_doc_data: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Preprocess the documentation data by tokenization, stemming\n",
    "    lemmatization, and stop-word removal.\n",
    "\n",
    "    Parameters:\n",
    "        cleaned_doc_data (list[str]) : the cleaned documentation data\n",
    "    \n",
    "    Returns:\n",
    "        proc_doc_data (list[str]) : preprocessed documentation data\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
